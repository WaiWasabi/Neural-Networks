{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional neural network (CNN)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7syOKglkKA0SJ5G0LQ5B4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WaiWasabi/Neural-Networks/blob/master/convolutional_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMDksSYT72Vn"
      },
      "source": [
        "# Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKcJUG0VG8Yt"
      },
      "source": [
        "class activation(object): # activation classes have two functions: fn(z) and prime(z) which return the activation function and its derivative, respectively.\n",
        "  def fn(z):\n",
        "    return z\n",
        "  def prime(z):\n",
        "    return z\n",
        "\n",
        "class relu(activation):\n",
        "  def fn(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "  def prime(z):\n",
        "    return (fn(z) + 0.00000001)/(fn(z) + 0.00000001)\n",
        "\n",
        "class sigmoid(activation):\n",
        "  def fn(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def prime(z):\n",
        "    return sigmoid.fn(z)*(1.0-sigmoid.fn(z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvx41cPDYwCw"
      },
      "source": [
        "# Cost Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZDzj25tY2LR"
      },
      "source": [
        "class Cost(object):\n",
        "  def fn(a, y):\n",
        "    return y-a\n",
        "  def prime(a, y):\n",
        "    return -1\n",
        "\n",
        "class Quadratic(Cost):\n",
        "  def fn(a, y):\n",
        "    return 0.5*np.linalg.norm(a-y)**2\n",
        "\n",
        "  def delta(a, y):\n",
        "    return a-y\n",
        "\n",
        "class CrossEntropy(Cost):\n",
        "  def fn(a, y):\n",
        "    pass\n",
        "\n",
        "  def delta(a, y):\n",
        "    return a-y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7B5tEUzS-9O"
      },
      "source": [
        "# Weight Initializers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U08yNIV5S-BK"
      },
      "source": [
        "  def default_weight_initializer(input_shape, output_shape):\n",
        "    return np.random.randn(output_shape, input_shape)\n",
        "  \n",
        "  def he_weight_initializer(input_shape, output_shape):\n",
        "    return default_weight_initializer(input_shape, output_shape) * np.sqrt(2/input_shape)\n",
        "  \n",
        "  def xavier_weight_initializer(input_shape, output_shape): # used for tanh activation.\n",
        "    return default_weight_initializer(input_shape, output_shape) * np.sqrt(1/input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP3gTgIv8UVd"
      },
      "source": [
        "# Network Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WviFyESKpFox"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class CNN(object):\n",
        "  def __init__(self, input_shape): #input shape for a single training example, a **tuple**.\n",
        "    self.model = []\n",
        "    self.input_shape = input_shape\n",
        "\n",
        "  def add(self, layer):\n",
        "    self.model.append(layer)\n",
        "  \n",
        "  def initializer(self, input_shape): # input_shape for a single input (no batch dim)\n",
        "    #for layer in self.model:\n",
        "      #input_shape = layer.initializer(input_shape)\n",
        "    for i in range(len(self.model)):\n",
        "      input_shape = self.model[i].initializer(input_shape)\n",
        "  \n",
        "  def SGD(self, train_data, mini_batch_size, epochs, lr, validation_data = None):\n",
        "    if validation_data != None:\n",
        "        test_input, test_label = validation_data\n",
        "    self.initialize()\n",
        "    for i in range(epochs):\n",
        "      random.shuffle(train_data)\n",
        "      mini_batches = [zip(*train_data[i:i+mini_batch_size]) for i in range(0, len(train_data), mini_batch_size)]\n",
        "      for mini_batch in mini_batches:\n",
        "        self.update_mini_batch(mini_batch, lr)\n",
        "      print(f\"Epoch {i+1} complete\")\n",
        "      if validation_data != None: print(\"Accuracy (%):\", self.evaluate(np.array(test_input), np.array(test_label)))\n",
        "\n",
        "  def update_mini_batch(self, mini_batch, lr):\n",
        "    train_input, train_label = mini_batch\n",
        "    a = np.array(train_input)\n",
        "    for layer in self.model:\n",
        "      a = layer.feedforward(a)\n",
        "    self.model[-1].set_labels(np.array(train_label))\n",
        "    for layer in self.model[::-1]:\n",
        "      a = layer.backprop(a, lr)\n",
        "\n",
        "  def initialize(self):\n",
        "    self.initializer(self.input_shape)\n",
        "  \n",
        "  def feedforward(self, a):\n",
        "    for layer in self.model:\n",
        "      a = layer.feedforward(a)\n",
        "    return a\n",
        "\n",
        "  def backprop(self, dCda, lr):\n",
        "    for layer in self.model[::-1]:\n",
        "      dCda = layer.backprop(dCda, lr)\n",
        "    return dCda\n",
        "  \n",
        "  def evaluate(self, test_input, test_label): #test_data is batched.\n",
        "    return sum([int(np.argmax(x)==y) for x, y in zip(self.feedforward(test_input), test_label)])/len(test_input)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lyWP9sZ8Z0G"
      },
      "source": [
        "# Layer Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdtM-TtChHjc"
      },
      "source": [
        "class Layer(object):\n",
        "  activations = {\n",
        "      \"default\":activation,\n",
        "      \"relu\":relu,\n",
        "      \"sigmoid\":sigmoid\n",
        "  }\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def feedforward(self, a):\n",
        "    self.set_input(a)\n",
        "    return a\n",
        "\n",
        "  def backprop(self, dCda, lr):\n",
        "    return dCda\n",
        "\n",
        "  def initializer(self, input_shape): # input_shape and output_shape are for single inputs, ignoring batches.\n",
        "    self.input_shape = input_shape\n",
        "    self.output_shape = self.get_output_shape(input_shape)\n",
        "    return self.output_shape\n",
        "  \n",
        "  def set_input(self, a):\n",
        "    self.a = a\n",
        "\n",
        "  def get_output_shape(self, input_shape):\n",
        "    return input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6DEgJzk8rvq"
      },
      "source": [
        "class ConvLayer(Layer):\n",
        "  def __init__(self, kernel_size, activation, stride = 1, zero_padding = 'valid'):   # still need to implement zero padding\n",
        "    \"\"\"kernel_size - a list of length 2 containing integers representing the x and y sizes of the filter\"\"\"\n",
        "    super().__init__()\n",
        "    self.activation = super().activations[activation]\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.zero_padding = zero_padding\n",
        "  \n",
        "  def feedforward(self, a): # a - a numpy array of dimensionality 4: (batch size, image x, image y, color channel)\n",
        "    self.set_input(a)\n",
        "    output = np.zeros([a.shape[0]] + [int((i-k)/self.stride) + 1 for i, k in zip(a.shape[1:3], self.kernel_size)] + [a.shape[3]])\n",
        "    a = np.transpose(a, (1,2,0,3))\n",
        "    output = np.transpose(output, (1,2,0,3)) # transpose output to (image x, image y, batch size, color channel) in order to set values in batches\n",
        "    for i in range(output.shape[0]):\n",
        "      for j in range(output.shape[1]):\n",
        "        output[i][j] = np.einsum(\"ijkl, ij -> kl\", a[i*self.stride:i*self.stride+self.kernel_size[0], j*self.stride:j*self.stride+self.kernel_size[1]], self.filter)\n",
        "    self.z = np.transpose(output, (2,0,1,3)) + self.biases\n",
        "    return self.activation.fn(self.z)\n",
        "  \n",
        "  def backprop(self, dconv, lr): # dconv is the matrix of partial derivatives of shape (batch size, conv x, conv y, color channel), conv x and conv y are the sizes of the convoluted output from the layer's feedforward.\n",
        "    delta = dconv * self.activation.prime(self.z) # delta is the derivative of the cost with respect to z.\n",
        "    dCdb = delta\n",
        "    dCdF = np.zeros(self.filter.shape + (delta.shape[0],)) # initialize shape of filter gradient with shape (filter x, filter y, batch size)\n",
        "    delta, a = (np.transpose(delta, (1,2,0,3)), np.transpose(self.a, (1,2,0,3))) # reshape to dimensions (x, y, batch, color channel)\n",
        "    dCda = np.zeros(a.shape)\n",
        "    for i in range(delta.shape[0]):\n",
        "      for j in range(delta.shape[1]):\n",
        "        x, y = (i*self.stride, j*self.stride)\n",
        "        dCdF += np.sum(delta[i][j] * a[x:x+self.kernel_size[0], y:y+self.kernel_size[1]], axis = 3) # a is the orginal input to the layer.\n",
        "        dCda[x:x+self.kernel_size[0], y:y+self.kernel_size[1]] += np.einsum(\"ij, kl -> ijkl\", self.filter, delta[i][j])\n",
        "    self.filter = self.filter - (lr/dCdF.shape[2])*np.sum(np.transpose(dCdF, (2,0,1)), axis = 0)\n",
        "    self.biases = self.biases - (lr/dCdb.shape[0])*np.sum(dCdb, axis = 0)\n",
        "    return np.transpose(dCda, (2,0,1,3))\n",
        "\n",
        "  \"\"\"backprop todo:\n",
        "  remove intermediate values dCdb and dCdF. Instead, update them directly\"\"\"\n",
        "\n",
        "  def initializer(self, input_shape):\n",
        "    self.input_shape = input_shape\n",
        "    self.output_shape = self.get_output_shape(input_shape)\n",
        "    self.filter = np.random.standard_normal(self.kernel_size) * np.sqrt(2/(input_shape[0]*input_shape[1]))\n",
        "    self.biases = np.random.standard_normal(self.output_shape)\n",
        "    #self.biases = np.zeros(self.output_shape)\n",
        "    return self.output_shape\n",
        "\n",
        "  def get_output_shape(self, input_shape):\n",
        "    return tuple([int((i-k)/self.stride)+1 for i, k in zip(input_shape[:2], self.kernel_size)]) + (self.input_shape[-1],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5LLaFo8pGz"
      },
      "source": [
        "class Flatten(Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  \n",
        "  def feedforward(self, a):\n",
        "    self.set_input(a)\n",
        "    return np.reshape(a.sum(axis = 3), (a.shape[0], -1, 1))\n",
        "    \n",
        "  def backprop(self, dreshape, lr):\n",
        "    return np.repeat(dreshape.reshape((dreshape.shape[0],) + self.input_shape[:-1] + (1,)), self.input_shape[-1], axis = 3) \n",
        "\n",
        "  def get_output_shape(self, input_shape):\n",
        "    return (np.prod(input_shape[:-1]).item(), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eprgY-y9841U"
      },
      "source": [
        "class Dense(Layer):\n",
        "  w_inits = {\n",
        "      \"default\":default_weight_initializer,\n",
        "      \"he\":he_weight_initializer,\n",
        "      \"xavier\":xavier_weight_initializer\n",
        "  }\n",
        "  def __init__(self, shape, activation = \"sigmoid\", weight_initialization = \"he\"): # shape is an integer specifying the # of output neurons.\n",
        "    super().__init__()\n",
        "    self.shape = shape\n",
        "    self.w_init = Dense.w_inits[weight_initialization]\n",
        "    self.activation = Layer.activations[activation]\n",
        "\n",
        "\n",
        "  def initializer(self, input_shape):\n",
        "    self.input_shape = input_shape\n",
        "    self.output_shape = self.get_output_shape(input_shape)\n",
        "    self.weights = self.w_init(input_shape[0], self.output_shape[0])\n",
        "    self.biases = np.random.standard_normal(self.output_shape)\n",
        "    return self.output_shape\n",
        "\n",
        "  def feedforward(self, a):\n",
        "    self.set_input(a)\n",
        "    self.z = np.matmul(self.weights, a) + self.biases\n",
        "    return  self.activation.fn(self.z)\n",
        "\n",
        "  def backprop(self, dCda, lr):\n",
        "    delta = dCda * self.activation.prime(self.z)\n",
        "    dCda = np.matmul(self.weights.transpose(), delta)\n",
        "    self.biases = self.biases - (lr/delta.shape[0])*np.sum(delta, axis = 0)\n",
        "    self.weights = self.weights - (lr/self.a.shape[0])*np.sum(np.matmul(delta, self.a.transpose([0,2,1])), axis = 0)\n",
        "    return dCda\n",
        "  \n",
        "  def get_output_shape(self, input_shape):\n",
        "    return (self.shape, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2eNHxF-Rg6X"
      },
      "source": [
        "class Output(Dense):\n",
        "  costs = {\n",
        "      \"cross entropy\":CrossEntropy,\n",
        "      \"quadratic\":Quadratic\n",
        "  }\n",
        "  def __init__(self, shape, activation = \"softmax\", weight_initialization = \"he\", cost = \"cross entropy\"):\n",
        "    super().__init__(shape = shape, activation = activation, weight_initialization = weight_initialization)\n",
        "    self.cost = Output.costs[cost]\n",
        "\n",
        "  def backprop(self, dCda, lr): #dCda is actually just the output a of the feedforward.\n",
        "    delta = self.cost.delta(dCda, self.train_label)\n",
        "    dCda = np.matmul(self.weights.transpose(), delta)    \n",
        "    self.biases = self.biases - (lr/delta.shape[0])*np.sum(delta, axis = 0)\n",
        "    self.weights = self.weights - (lr/self.a.shape[0])*np.sum(np.matmul(delta, self.a.transpose([0,2,1])), axis = 0)\n",
        "    return dCda\n",
        "  \n",
        "  def set_labels(self, train_label):\n",
        "    self.train_label = train_label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N49PONFI49ES"
      },
      "source": [
        "# Import and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBuvLeVIk63h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2476ae38-58c9-45b9-ab45-76213ca7dc23"
      },
      "source": [
        "def to_one_hot(data, max):\n",
        "  output = []\n",
        "  for index in data:\n",
        "    one_hot = np.zeros((max, 1))\n",
        "    one_hot[index][0] = 1\n",
        "    output.append(one_hot)\n",
        "  return np.array(output)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "#x_train = np.array([x.reshape(-1, 1)/255 for x in x_train])\n",
        "#x_test = np.array([x.reshape(-1, 1)/255 for x in x_test])\n",
        "\n",
        "x_train = np.array([np.expand_dims(x/255, 2) for x in x_train])\n",
        "x_test = np.array([np.expand_dims(x/255, 2) for x in x_test])\n",
        "\n",
        "x_train, x_validate = (x_train[0:50000], x_train[50000:60000])\n",
        "y_train, y_validate = (y_train[0:50000], y_train[50000:60000])\n",
        "\n",
        "y_train = to_one_hot(y_train, 10)\n",
        "\n",
        "train_batch = [(x, y) for x, y in zip(x_train, y_train)]\n",
        "test_batch = [(x, y) for x, y in zip(x_test, y_test)]\n",
        "validate_batch = [(x, y) for x, y in zip(x_validate, y_validate)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKaSg_3N5FQq"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBsOWIJ7KwtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5743d595-1e2b-4edf-a710-c2651a26c4a8"
      },
      "source": [
        "network = CNN((28,28,1))\n",
        "network.add(ConvLayer([2,2], \"sigmoid\", stride = 2))\n",
        "network.add(Flatten())\n",
        "network.add(Dense(60, activation = 'sigmoid', weight_initialization = 'he'))\n",
        "network.add(Output(10, activation = 'sigmoid', weight_initialization = 'he', cost = 'cross entropy'))\n",
        "\n",
        "\"\"\"\n",
        "network.model[0].input_shape = (5,5,1)\n",
        "network.model[0].output_shape = (2,2,1)\n",
        "network.model[0].filter = np.array([[1,0],[1,0]])\n",
        "network.model[0].biases = np.array([[[0.2], [0.3]], [[0.8], [0.4]]])\n",
        "\n",
        "network.model[1].input_shape = (2,2,1)\n",
        "network.model[1].output_shape = (4,1)\n",
        "\n",
        "network.model[2].input_shape = (4,1)\n",
        "network.model[2].output_shape = (5,1)\n",
        "network.model[2].weights = np.array([[0.8,0.4,0.3,0.5],[0.1,0.7,0.2,0.9],[0.1,0.2,0.1,0.3],[0.2,0.3,0.7,0.6],[0.5,0.4,0.8,0.6]])\n",
        "network.model[2].biases = np.array([[0.2], [0.1], [0.3], [0.3], [0.5]])\n",
        "\n",
        "network.model[3].input_shape = (5,1)\n",
        "network.model[3].output_shape = (3,1)\n",
        "network.model[3].weights = np.array([[0.1,0.2,0.3,0.4,0.5],[0.5,0.4,0.3,0.2,0.1],[0.2,0.3,0.5,0.4,0.1]])\n",
        "network.model[3].biases = np.array([[0.1],[0.2],[0.3]])\n",
        "\"\"\"\n",
        "validation = zip(*validate_batch)\n",
        "network.SGD(train_batch, 32, 15, 0.6, validation)\n",
        "\n",
        "\"\"\"\n",
        "network.initialize()\n",
        "\n",
        "random.shuffle(train_batch)\n",
        "mini_batches = [zip(*train_batch[i:i+30]) for i in range(0, len(train_batch), 30)]\n",
        "\n",
        "count = 0\n",
        "for mini_batch in mini_batches:\n",
        "  train_input, train_label = mini_batch\n",
        "  network.model[-1].set_labels(np.array(train_label))\n",
        "  ff = network.feedforward(np.array(train_input))\n",
        "  network.backprop(ff, 10)\n",
        "  count += 1\n",
        "  print(count)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "a = np.array([[[[0],[1],[2],[3],[2]],[[4],[0],[1],[2],[1]],[[1],[3],[2],[3],[0]],[[3],[1],[0],[2],[3]],[[2],[2],[3],[0],[4]]]])\n",
        "print(a.shape)\n",
        "a = network.model[0].feedforward(a)\n",
        "print(a.shape)\n",
        "a = network.model[1].feedforward(a)\n",
        "print(a.shape)\n",
        "a = network.model[2].feedforward(a)\n",
        "print(a.shape)\n",
        "a = network.model[3].feedforward(a)\n",
        "network.model[3].set_labels(np.array([[[0], [1], [0]]]))\n",
        "a = network.model[3].backprop(a, 1)\n",
        "a = network.model[2].backprop(a, 1)\n",
        "a = network.model[1].backprop(a, 1)\n",
        "a = network.model[0].backprop(a, 1)\n",
        "print(a)\n",
        "print(network.model[0].filter)\n",
        "print(network.model[0].biases)\n",
        "\"\"\"\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 complete\n",
            "Accuracy (%): 87.92\n",
            "Epoch 2 complete\n",
            "Accuracy (%): 92.49000000000001\n",
            "Epoch 3 complete\n",
            "Accuracy (%): 94.17999999999999\n",
            "Epoch 4 complete\n",
            "Accuracy (%): 94.39\n",
            "Epoch 5 complete\n",
            "Accuracy (%): 95.84\n",
            "Epoch 6 complete\n",
            "Accuracy (%): 96.22\n",
            "Epoch 7 complete\n",
            "Accuracy (%): 96.16\n",
            "Epoch 8 complete\n",
            "Accuracy (%): 96.78999999999999\n",
            "Epoch 9 complete\n",
            "Accuracy (%): 96.75\n",
            "Epoch 10 complete\n",
            "Accuracy (%): 96.74000000000001\n",
            "Epoch 11 complete\n",
            "Accuracy (%): 96.71\n",
            "Epoch 12 complete\n",
            "Accuracy (%): 96.88\n",
            "Epoch 13 complete\n",
            "Accuracy (%): 96.97\n",
            "Epoch 14 complete\n",
            "Accuracy (%): 96.98\n",
            "Epoch 15 complete\n",
            "Accuracy (%): 97.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0vhxcuGmept"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}